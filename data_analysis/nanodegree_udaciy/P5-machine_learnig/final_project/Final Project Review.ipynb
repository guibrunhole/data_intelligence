{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Identificar fraude no email da Enron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira Parte: Fundamentação Teórica e Explicação do Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo desse projeto é determinar se um funcionário é ou não um funcionário de interesse (POI). Um funcionário de interesse é um funcionário que participou do escândalo da empresa Enron. \n",
    "\n",
    "Para isso iremos usar diversos métodos que foram aprendidos no módulo de *Machine Learning*, mais especificamente usaremos o conjunto de métodos **sklearn**, que contém inúmeras funcionalidades para esse aprendizado :)\n",
    "\n",
    "Meu código final está no arquivo *poi_id.py* que deve ser executado primeiro para exportar os conjuntos de dados e em seguida deve-se executar o *tester.py*.\n",
    "\n",
    "Machine Learning foi a solução ideal para a resolução desse problema pois para sabermos se um funcionário está ou não envolvido no escândalo, nós precisamos que o nosso código saiba o que é isso e como classificar isso.\n",
    "Existem diversos tipos de ML tais como recomendação (que Netflix e Amazon usam e abusam), detecção de anomalias, prevenção de fraude, agrupamento e diversos outros.\n",
    "\n",
    "Para a resolução desse problema eu testei **4 algoritmos** que aprendi ao longo do módulo:\n",
    "- **Decision Tree:** Esse algoritmo pode ser comparado ao *CASE WHEN... THEN.. ELSE... END\". Basicamente nós aplicamos certas regras nos dados e dependendo de cada valor, um decisão é tomada. Esse algoritmo é bastante usado em pesquisas operacionais.\n",
    "- **Random Forest:** É um *ensemble learning* supervisionado, que é comumente usado em problemas de classificação, detecção de anomalias e redes neurais.\n",
    "- **SDG:** Esse método é usado em otimização e tem como objetivo encontrar o mínimo local de uma função.\n",
    "- **NaiveBayes:** É bastante usado em *text learning* \n",
    "\n",
    "Além dos 4 métodos apresentados acima, existem alguns cuidados, ou melhor, tratativas que devem ser aplicadas no dataset antes de treinar o algoritmo.\n",
    "\n",
    "Um ponto bastante importante é a **remoção de outliers**. Classificamos um valor como outlier quando ele está muito discrepante do restante dos valores. Existem algumas técnicas para a detecção/exclusão, uma bastante conhecida e que aprendi aqui no Nanodegree é o [Interquartile Range (IQR)](https://en.wikipedia.org/wiki/Interquartile_range).\n",
    "\n",
    "Nesse projeto tive que remover um valor do conjunto de dados. \n",
    "   - `data_dict.pop('TOTAL')`: *TOTAL* não é uma pessoa e isso estava poluindo a análise.\n",
    "   \n",
    "Outro ponto de limpeza dos dados que precisei fazer foi realizar um replace em todos os registros cujos valores eram **NaN**. Isso poderia afetar bastante as análises, então decidi apenas substituir por **0**:\n",
    "   - `final = df[cols].copy().applymap(lambda x: 0  if x == 'NaN' else x)`\n",
    "   \n",
    "Agora sobre as **features** que foram analizadas aqui, utilizei o algoritmo [SelectPercentile](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html) e [FeatureSelection](http://scikit-learn.org/stable/modules/feature_selection.html) para saber quais features mais eram relevantes para a descoberta da nossa pergunta.\n",
    "O primeiro foi para pegar um percentual do conjunto de dados e o segundo foi utilizado para a seleção das features de fato :)\n",
    "\n",
    "Tendo nossas features selecionadas e armazenadas em *features_list*, executei o seguinte código para fazer a divisão em **labels** e **features** para que possamos começar a testar os algoritmos de ML!\n",
    "\n",
    "```\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "```\n",
    "\n",
    "Esse conjunto *featureFormat* foi provido pela Udacity e pode ser encontrado [aqui](https://github.com/udacity/ud120-projects/blob/master/tools/feature_format.py).\n",
    "\n",
    "Por fim, utilizei o método de [cross_validation](http://scikit-learn.org/stable/modules/cross_validation.html) para realizarmos a divisão de nosso dataset em dois, um para teste e outro para treinamento. \n",
    "Realizar essa divisão é essencial, pois ele nos ajuda a evitarmos bastante a ocorrência de *overfitting*, porém alguns cuidados devem ser tomados, como por exemplo, a divisão precisa ser randômica, para que não treinamos nosso algoritmo e deixe ele com um viés mais forte. \n",
    "Para isso, dentro desse método, existe o [test_train_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) que faz essa divisão e já leva em conta esse cuidado.\n",
    "\n",
    "Aqui eu fiz a divisão clássica de 30% para teste e 70% para treino.\n",
    "\n",
    "Na segunda parte entrarei um pouco mais detalhado no código e em alguns testes e tunings que fiz com alguns parâmetros para que fosse possível obter a melhor resposta :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda Parte: Código executado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../ud120-projects/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.76691\tPrecision: 0.35142\tRecall: 0.33350\tF1: 0.34223\tF2: 0.33694\n",
      "\tTotal predictions: 11000\tTrue positives:  667\tFalse positives: 1231\tFalse negatives: 1333\tTrue negatives: 7769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## DecisionTreeeClassifier\n",
    "run tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.82473\tPrecision: 0.54380\tRecall: 0.22350\tF1: 0.31680\tF2: 0.25334\n",
      "\tTotal predictions: 11000\tTrue positives:  447\tFalse positives:  375\tFalse negatives: 1553\tTrue negatives: 8625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## DecisionTreeeClassifier\n",
    "run tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\tAccuracy: 0.58045\tPrecision: 0.16293\tRecall: 0.31600\tF1: 0.21500\tF2: 0.26602\n",
      "\tTotal predictions: 11000\tTrue positives:  632\tFalse positives: 3247\tFalse negatives: 1368\tTrue negatives: 5753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SDGClassifier\n",
    "run tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.83255\tPrecision: 0.56280\tRecall: 0.35400\tF1: 0.43462\tF2: 0.38237\n",
      "\tTotal predictions: 11000\tTrue positives:  708\tFalse positives:  550\tFalse negatives: 1292\tTrue negatives: 8450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## NaiveBayesClassifier\n",
    "run tester.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode-se perceber, aqui não precisei tunar o modelo para conseguir o mínimo requerido para o projeto (0.3 para ambas as métricas).\n",
    "\n",
    "Quando calculamos a métrica de precisão, queremos saber qual é a razão entre os eventos que previmos corretamente com todos os outros que eram corretos, porém nosso algoritmo ou fez a previsão correta, ou classificou como negativo. Já recall é quando queremos saber a taxa de verdadeiros positivos no problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um tratamento que fiz foi selecionar o melhor *percentile* para o conjunto de dados. O que esse método faz é selecionar as **features de acordo com o seu score**.\n",
    "\n",
    "Seguem abaixo alguns testes que fiz até chegar no melhor modelo :)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### SelectPercentile: 10\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.82182\tPrecision: 0.51818\tRecall: 0.28500\tF1: 0.36774\tF2: 0.31319\n",
    "\tTotal predictions: 11000\tTrue positives:  570\tFalse positives:  530\tFalse negatives: 1430\tTrue negatives: 8470\n",
    "\n",
    "#### SelectPercentile: 20\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.82391\tPrecision: 0.52704\tRecall: 0.30700\tF1: 0.38799\tF2: 0.33497\n",
    "\tTotal predictions: 11000\tTrue positives:  614\tFalse positives:  551\tFalse negatives: 1386\tTrue negatives: 8449\n",
    "\n",
    "#### SelectPercentile: 25 => Best Option!!! :-)\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.83255\tPrecision: 0.56280\tRecall: 0.35400\tF1: 0.43462\tF2: 0.38237\n",
    "\tTotal predictions: 11000\tTrue positives:  708\tFalse positives:  550\tFalse negatives: 1292\tTrue negatives: 8450\n",
    "\n",
    "#### SelectPercentile: 30\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.82782\tPrecision: 0.53991\tRecall: 0.35850\tF1: 0.43089\tF2: 0.38433\n",
    "\tTotal predictions: 11000\tTrue positives:  717\tFalse positives:  611\tFalse negatives: 1283\tTrue negatives: 8389\n",
    "\n",
    "#### SelectPercentile: 40\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.81817\tPrecision: 0.43627\tRecall: 0.31150\tF1: 0.36348\tF2: 0.33040\n",
    "\tTotal predictions: 12000\tTrue positives:  623\tFalse positives:  805\tFalse negatives: 1377\tTrue negatives: 9195\n",
    "\n",
    "#### SelectPercentile: 50\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.75583\tPrecision: 0.27449\tRecall: 0.28300\tF1: 0.27868\tF2: 0.28126\n",
    "\tTotal predictions: 12000\tTrue positives:  566\tFalse positives: 1496\tFalse negatives: 1434\tTrue negatives: 8504"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eu usei o NaiveBayes como teste para achar o melhor Percentile :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meu conjunto de features final ficou sendo o seguinte:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['poi', 'deferred_income', 'bonus', 'total_stock_value', 'salary', 'exercised_stock_options']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Terceira Parte: Possíveis problemas com o conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui irei pontuar em tópicos alguns problemas que encontrei nesse conjunto de dados:\n",
    "   - Inconsistência nos e-mails\n",
    "   - Diferentes conjuntos de dados podem introduzir diferentes bias e erros\n",
    "   - POI pode não estar no conjunto de dados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
