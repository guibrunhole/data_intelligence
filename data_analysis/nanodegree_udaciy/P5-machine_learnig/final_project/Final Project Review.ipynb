{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Identificar fraude no email da Enron \n",
    "\n",
    "O objetivo desse projeto é determinar se um funcionário é ou não um funcionário de interesse (POI). Um funcionário de interesse é um funcionário que participou do escândalo da empresa Enron. \n",
    "\n",
    "Para isso iremos usar diversos métodos que foram aprendidos no módulo de *Machine Learning*, mais especificamente usaremos o conjunto de métodos **sklearn**, que contém inúmeras funcionalidades para esse aprendizado :)\n",
    "\n",
    "Meu código final está no arquivo *poi_id.py* que deve ser executado primeiro para exportar os conjuntos de dados e em seguida deve-se executar o *tester.py*.\n",
    "\n",
    "Primeiro irei mostrar as saídas dos algoritmos que usei e qual escolhi para o final. Em seguida meus comentários finais sobre o projeto (além dos que já existem no código)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../ud120-projects/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.76691\tPrecision: 0.35142\tRecall: 0.33350\tF1: 0.34223\tF2: 0.33694\n",
      "\tTotal predictions: 11000\tTrue positives:  667\tFalse positives: 1231\tFalse negatives: 1333\tTrue negatives: 7769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## DecisionTreeeClassifier\n",
    "run tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.82473\tPrecision: 0.54380\tRecall: 0.22350\tF1: 0.31680\tF2: 0.25334\n",
      "\tTotal predictions: 11000\tTrue positives:  447\tFalse positives:  375\tFalse negatives: 1553\tTrue negatives: 8625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## DecisionTreeeClassifier\n",
    "run tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\tAccuracy: 0.58045\tPrecision: 0.16293\tRecall: 0.31600\tF1: 0.21500\tF2: 0.26602\n",
      "\tTotal predictions: 11000\tTrue positives:  632\tFalse positives: 3247\tFalse negatives: 1368\tTrue negatives: 5753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SDGClassifier\n",
    "run tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.83255\tPrecision: 0.56280\tRecall: 0.35400\tF1: 0.43462\tF2: 0.38237\n",
      "\tTotal predictions: 11000\tTrue positives:  708\tFalse positives:  550\tFalse negatives: 1292\tTrue negatives: 8450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## NaiveBayesClassifier\n",
    "run tester.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode-se perceber, aqui não precisei tunar o modelo para conseguir o mínimo requerido para o projeto (0.3 para ambas as métricas).\n",
    "\n",
    "Quando calculamos a métrica de precisão, queremos saber qual é a razão entre os eventos que previmos corretamente com todos os outros que eram corretos, porém nosso algoritmo ou fez a previsão correta, ou classificou como negativo. Já recall é quando queremos saber a taxa de verdadeiros positivos no problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um tratamento que fiz foi selecionar o melhor *percentile* para o conjunto de dados. O que esse método faz é selecionar as **features de acordo com o seu score**.\n",
    "\n",
    "Seguem abaixo alguns testes que fiz até chegar no melhor modelo :)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### SelectPercentile: 10\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.82182\tPrecision: 0.51818\tRecall: 0.28500\tF1: 0.36774\tF2: 0.31319\n",
    "\tTotal predictions: 11000\tTrue positives:  570\tFalse positives:  530\tFalse negatives: 1430\tTrue negatives: 8470\n",
    "\n",
    "#### SelectPercentile: 20\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.82391\tPrecision: 0.52704\tRecall: 0.30700\tF1: 0.38799\tF2: 0.33497\n",
    "\tTotal predictions: 11000\tTrue positives:  614\tFalse positives:  551\tFalse negatives: 1386\tTrue negatives: 8449\n",
    "\n",
    "#### SelectPercentile: 25 => Best Option!!! :-)\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.83255\tPrecision: 0.56280\tRecall: 0.35400\tF1: 0.43462\tF2: 0.38237\n",
    "\tTotal predictions: 11000\tTrue positives:  708\tFalse positives:  550\tFalse negatives: 1292\tTrue negatives: 8450\n",
    "\n",
    "#### SelectPercentile: 30\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.82782\tPrecision: 0.53991\tRecall: 0.35850\tF1: 0.43089\tF2: 0.38433\n",
    "\tTotal predictions: 11000\tTrue positives:  717\tFalse positives:  611\tFalse negatives: 1283\tTrue negatives: 8389\n",
    "\n",
    "#### SelectPercentile: 40\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.81817\tPrecision: 0.43627\tRecall: 0.31150\tF1: 0.36348\tF2: 0.33040\n",
    "\tTotal predictions: 12000\tTrue positives:  623\tFalse positives:  805\tFalse negatives: 1377\tTrue negatives: 9195\n",
    "\n",
    "#### SelectPercentile: 50\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.75583\tPrecision: 0.27449\tRecall: 0.28300\tF1: 0.27868\tF2: 0.28126\n",
    "\tTotal predictions: 12000\tTrue positives:  566\tFalse positives: 1496\tFalse negatives: 1434\tTrue negatives: 8504"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eu usei o NaiveBayes como teste para achar o melhor Percentile :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meu conjunto de features final ficou sendo o seguinte:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['poi', 'deferred_income', 'bonus', 'total_stock_value', 'salary', 'exercised_stock_options']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
