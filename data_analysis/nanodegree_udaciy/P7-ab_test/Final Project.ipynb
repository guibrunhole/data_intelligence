{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Overview: Free Trial Screener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of this experiment, Udacity courses currently have two options on the course overview page: \"start free trial\", and \"access course materials\". If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first. If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.\n",
    "\n",
    "In the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course. If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead. [This screenshot](img/experiment.png) shows what the experiment looks like.\n",
    "\n",
    "The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough time—without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n",
    "\n",
    "The unit of diversion is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Design\n",
    "\n",
    "### Metric Choice\n",
    "\n",
    "#### Invariant metrics\n",
    "- **Number of cookies:** That is, number of unique cookies to view the course overview page. (dmin=3000)\n",
    "- **Number of clicks:** That is, number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). (dmin=240)\n",
    "- **Click through probability:** That is, number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page. (dmin=0.01)\n",
    "\n",
    "Sanity Check is useful when we want to make sure that the data filtered for experiment and control group is the same. This can be done using the right invariance metric. These three metrics shouldn't change because it's outside of the experiment, in a sense that these metric calculated all before the experiment begin.\n",
    "\n",
    "Number of cookies who views the page should be the same when Udacity experiment. They haven't click the \"Start Now\" button and see \"Free Trial Screener\" experiment. So number of cookies can be used as invariant metrics. When users click the button, they also haven't yet see the experiment that Udacity does, so number of clicks shouldn't change between experiment and control groups.\n",
    "\n",
    "Since the experiments only occurs after the users click the \"Start Now\" button, its click-through-probability also have to be the same for each experiment and control group. We know that number of cookies and number of clicks has to be the same, then click-thorough-probability also has to be the same.\n",
    "Besides cookie-id, there is also user-id. But user-id is not a good invariant, because Udacity also open to unregistered users to view page until after click of a button.\n",
    "\n",
    "#### Evaluation metrics\n",
    "- **Gross conversion:** That is, number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. (dmin= 0.01)\n",
    "- **Net conversion:** That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. (dmin= 0.0075)\n",
    "\n",
    "\n",
    "For evaluation metrics, I choose **Gross Conversion**, **Retention**, and **Net Conversion**. All of these metrics are a good evaluation metrics since they change when the experiment change, and since each of the metrics has user-ids as the unit of analysis, should be much smaller standard error since Udacity also using it as the cookie of diversion.\n",
    "\n",
    "**Gross conversion** is the number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. After the visitors click the button, they should see the screener, hence the warning. It should be makes other visitors that doesn't have serious commitment back down and cancel it right away.\n",
    "\n",
    "**Retention** is number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids to complete checkout. The experiment intend to focus the visitors that only want to make a serious commitment. The retention rate should be higher for experiment group than the control group.\n",
    "\n",
    "**Net conversion** is number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. Net Conversion also true, since the experiment intend to see higher conversion rate for students to continue (at least make one payment) than the users that only click the button, that doesn't even see the warning experiment given.\n",
    "\n",
    "Ouf of these metrics, Retention turns out have a longer duration, which is 118 days. This takes too long, and it's not something Udacity willing to give for the experiment. So *Retention will be excluded*.\n",
    "\n",
    "The first part is what Gross Conversion does, we should expect after the experiment, Gross Conversion shows significantly reduce the number who left trial because they don’t have time commitment. The experiment group should be significantly different than control group. The second part is what Net Conversion does, we should expect after experiment, the metric shows insignificantly reduce the number of students who at least make one payment. The experiment group should not significantly different than control group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using baseline values we have:\n",
    "\n",
    "- Unique cookies to view course overview page per day:\t**40000**\n",
    "- Unique cookies to click \"Start free trial\" per day:\t**3200**\n",
    "- Enrollments per day:\t**660**\n",
    "- Click-through-probability on \"Start free trial\":\t**0.08**\n",
    "- Probability of enrolling, given click:\t**0.20625**\n",
    "- Probability of payment, given enroll:\t**0.53**\n",
    "- Probability of payment, given click\t**0.1093125**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate standard deviation, we use this formula:\n",
    "\n",
    "$$Formula = np.sqrt(p * (1-p) / n)$$\n",
    "\n",
    "and using baseline data above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a sample with 5000 cookies, so we need number of users who click \"Start now\" button:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5000\n",
    "clicks = 5000*0.08\n",
    "\n",
    "clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation for **Gross Conversion** is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0202"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.20625\n",
    "round(np.sqrt(p * (1-p) / clicks),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for **Net Conversion**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0156"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.1093125\n",
    "round(np.sqrt(p * (1-p) / clicks),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizing\n",
    "\n",
    "### Number of Samples vs. Power\n",
    "\n",
    "- Gross Conversion. **Baseline**: 0.20625 - **dmin**: 0.01\n",
    "- Net Conversion. **Baseline**: 0.1093125 - **dmin**: 0.0075\n",
    "- Not using Bonferroni correction.\n",
    "- Using alpha = 0.05 and beta = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used [this site](http://www.evanmiller.org/ab-testing/sample-size.html) to calculate those metrics.\n",
    "\n",
    "- **Gross Conversion**: 25,835 cookies who clicks\n",
    "- **Net Conversion**: 27,411 cookies who clicks\n",
    "\n",
    "To calculate the total page views I'll use the bigger number, so the minimum required cookies is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total page view is:  685275\n"
     ]
    }
   ],
   "source": [
    "print 'The total page view is: ', int((27411 * 2) / 0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration vs. Exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraction of experiment exposure to Udacity visitors will be 80%. The experiment isn't risky enough that may potentially leaked as blog news or article. It doesn't really big a news, as Udacity only want to put little warning to the users. Because only 40000 pageviews each day can be gathered, the duration will be 22 days.\n",
    "\n",
    "This is where Retention metric fail for our evaluation metrics. It has a longer duration, which is 118 days. This takes too long, and it's not something Udacity willing to give for the experiment. So Retention will be excluded.\n",
    "\n",
    "- **Fraction**: 0.8 (Low risk)\n",
    "- **Duration**: 22 days (40000 pageviews/day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "\n",
    "For each of your invariant metrics, give the 95% confidence interval for the value you expect to observe, the actual observed value, and whether the metric passes your sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of Cookies**\n",
    "- Bounds = (0.4988,0.5012)\n",
    "- Observed = 0.5006\n",
    "- Passes? Yes\n",
    "\n",
    "**Number of clicks on “Start free trial”**\n",
    "- Bounds = (0.4959,0.5041)\n",
    "- Observed = 0.5005\n",
    "- Passes? Yes\n",
    "\n",
    "**Click-through-probability on “Start free trial”**\n",
    "- Bounds = (0.0812,0.0830)\n",
    "- Observed = 0.0821\n",
    "- Passes? Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sanity checks have been passed! :)\n",
    "\n",
    "We did this because sanity checks ensure that both experiment and groups have equal proportion.\n",
    "\n",
    "Now I'll see the experiment and control data from [Experiment](experiment.csv) and [Control](control.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experiment = pd.read_csv('experiment.csv', sep = ',')\n",
    "control = pd.read_csv('control.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7716</td>\n",
       "      <td>686</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9288</td>\n",
       "      <td>785</td>\n",
       "      <td>116.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10480</td>\n",
       "      <td>884</td>\n",
       "      <td>145.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9867</td>\n",
       "      <td>827</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793</td>\n",
       "      <td>832</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0  Sat, Oct 11       7716     686        105.0      34.0\n",
       "1  Sun, Oct 12       9288     785        116.0      91.0\n",
       "2  Mon, Oct 13      10480     884        145.0      79.0\n",
       "3  Tue, Oct 14       9867     827        138.0      92.0\n",
       "4  Wed, Oct 15       9793     832        140.0      94.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0  Sat, Oct 11       7723     687        134.0      70.0\n",
       "1  Sun, Oct 12       9102     779        147.0      70.0\n",
       "2  Mon, Oct 13      10511     909        167.0      95.0\n",
       "3  Tue, Oct 14       9871     836        156.0     105.0\n",
       "4  Wed, Oct 15      10014     837        163.0      64.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to calculate total views and total clicks in both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_views = experiment['Pageviews'].sum()\n",
    "experiment_clicks = experiment['Clicks'].sum()\n",
    "\n",
    "control_views = control['Pageviews'].sum()\n",
    "control_clicks = control['Clicks'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiment views:  344660\n",
      "Total experiment clicks:  28325\n",
      "Total control views:  345543\n",
      "Total control clicks:  28378\n"
     ]
    }
   ],
   "source": [
    "print 'Total experiment views: ', experiment_views\n",
    "print 'Total experiment clicks: ', experiment_clicks\n",
    "print 'Total control views: ', control_views\n",
    "print 'Total control clicks: ', control_clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll do a sanity check in our data. \n",
    "\n",
    "First I'll use clicks and after views. We expect that the sanity will be closer to 0.5, so this means that we have equal proportion in both files :)\n",
    "\n",
    "Let's see!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Views sanity check:  0.498820392149 0.501179607851\n",
      "Actual proportion in your file:  0.500639666881\n"
     ]
    }
   ],
   "source": [
    "goal = 0.5\n",
    "SE = np.sqrt((goal*(1-goal))/(control_views + experiment_views))\n",
    "ME = 1.96 * SE\n",
    "\n",
    "print 'Views sanity check: ', goal-ME, goal+ME\n",
    "print 'Actual proportion in your file: ', float(control_views)/(control_views+experiment_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicks sanity check:  0.495884495724 0.504115504276\n",
      "Actual proportion in your file:  0.500467347407\n"
     ]
    }
   ],
   "source": [
    "goal = 0.5\n",
    "SE = np.sqrt((goal*(1-goal))/(control_clicks + experiment_clicks))\n",
    "ME = 1.96 * SE\n",
    "\n",
    "print 'Clicks sanity check: ', goal-ME, goal+ME\n",
    "print 'Actual proportion in your file: ', float(control_clicks)/(control_clicks+experiment_clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Click Through Probabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTP sanity check:  0.0812103597525 0.0830412673966\n",
      "Actual CTP in your file:  0.0821824406662\n"
     ]
    }
   ],
   "source": [
    "ctp_control = float(control_clicks)/control_views\n",
    "ctp_experiment = float(experiment_clicks)/experiment_views\n",
    "\n",
    "SE = np.sqrt(ctp_control*(1-ctp_control)/control_views)\n",
    "ME = 1.96 * SE\n",
    "\n",
    "print 'CTP sanity check: ', ctp_control-ME, ctp_control+ME\n",
    "print 'Actual CTP in your file: ', ctp_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we saw, we have passed all of the sanity checks, so I'll keep going to do our experiment :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect Size Tests\n",
    "\n",
    "For each of your evaluation metrics, give a 95% confidence interval around the difference between the experiment and control groups. Indicate whether each metric is statistically and practically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gross Conversion**\n",
    "- Bounds = (-0.0291233583354,-0.0119863908253)\n",
    "- Observed = 0.00856848375504\n",
    "\n",
    "**Net Conversion**\n",
    "- Bounds = (-0.00717728190218, 0.00123178641406)\n",
    "- Observed = 0.00420453415812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Clicks:  28378\n",
      "Control Enrollments:  3785\n",
      "Experiment Clicks:  28325\n",
      "Experiment Enrollments:  3423\n"
     ]
    }
   ],
   "source": [
    "control_clicks = control['Clicks'].dropna().sum()\n",
    "control_enrollments = control['Enrollments'].dropna().sum()\n",
    "\n",
    "experiment_clicks = experiment['Clicks'].dropna().sum()\n",
    "experiment_enrollments = experiment['Enrollments'].dropna().sum()\n",
    "\n",
    "print 'Control Clicks: ', int(control_clicks)\n",
    "print 'Control Enrollments: ', int(control_enrollments)\n",
    "print 'Experiment Clicks: ', int(experiment_clicks)\n",
    "print 'Experiment Enrollments: ', int(experiment_enrollments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control file result:  0.218874689181\n",
      "Experiment file result:  0.1983198146\n"
     ]
    }
   ],
   "source": [
    "print 'Control file result: ', control_enrollments/control_clicks\n",
    "print 'Experiment file result: ', experiment_enrollments/experiment_clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll see if our standard deviation is ok :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020554874580361565"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first of all, we'll get the difference between control and experiment files\n",
    "\n",
    "diff = experiment_enrollments/experiment_clicks - control_enrollments/control_clicks\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *diff* is above of *d_min* that equal 0.01, minimum detectable effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00856848375504\n",
      "-0.0291233583354 -0.0119863908253\n"
     ]
    }
   ],
   "source": [
    "prop = (control_enrollments+experiment_enrollments)/(control_clicks+experiment_clicks)\n",
    "SE = np.sqrt((prop*(1-prop)) * (1/float(control_clicks) + 1/float(experiment_clicks)))\n",
    "ME = 1.96 * SE\n",
    "\n",
    "print ME\n",
    "\n",
    "print diff-ME, diff+ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And one more comment is that the observed diff is outside the confidance interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Clicks:  28378\n",
      "Control Payments:  2033\n",
      "Experiment Clicks:  28325\n",
      "Experiment Payments:  1945\n"
     ]
    }
   ],
   "source": [
    "control_clicks = control['Clicks'].dropna().sum()\n",
    "control_payments = control['Payments'].dropna().sum()\n",
    "\n",
    "experiment_clicks = experiment['Clicks'].dropna().sum()\n",
    "experiment_payments = experiment['Payments'].dropna().sum()\n",
    "\n",
    "print 'Control Clicks: ', int(control_clicks)\n",
    "print 'Control Payments: ', int(control_payments)\n",
    "print 'Experiment Clicks: ', int(experiment_clicks)\n",
    "print 'Experiment Payments: ', int(experiment_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control file result:  0.0716400028191\n",
      "Experiment file result:  0.068667255075\n"
     ]
    }
   ],
   "source": [
    "print 'Control file result: ', control_payments/control_clicks\n",
    "print 'Experiment file result: ', experiment_payments/experiment_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0029727477440631422"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first of all, we'll get the difference between control and experiment files\n",
    "\n",
    "diff = experiment_payments/experiment_clicks - control_payments/control_clicks\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00420453415812\n",
      "-0.00717728190218 0.00123178641406\n"
     ]
    }
   ],
   "source": [
    "prop = (control_payments+experiment_payments)/(control_clicks+experiment_clicks)\n",
    "SE = np.sqrt((prop*(1-prop)) * (1/float(control_clicks) + 1/float(experiment_clicks)))\n",
    "ME = 1.96 * SE\n",
    "\n",
    "print ME\n",
    "\n",
    "print diff-ME, diff+ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign Tests\n",
    "\n",
    "For each of your evaluation metrics, do a sign test using the day-by-day data, and report the p-value of the sign test and whether the result is statistically significant. Sign Test is also a test that must be confirmed with effect size test.\n",
    "\n",
    "To compare day-by-day, I'll create a new DataFrame with 4 columns:\n",
    "- Control probability Gross\n",
    "- Experiment probability Gross\n",
    "- Control probability Net\n",
    "- Experiment probability Net\n",
    "\n",
    "Let's do this! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>control_gross</th>\n",
       "      <th>control_net</th>\n",
       "      <th>experiment_gross</th>\n",
       "      <th>experiment_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.195051</td>\n",
       "      <td>0.101892</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.049563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188703</td>\n",
       "      <td>0.089859</td>\n",
       "      <td>0.147771</td>\n",
       "      <td>0.115924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.183718</td>\n",
       "      <td>0.104510</td>\n",
       "      <td>0.164027</td>\n",
       "      <td>0.089367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186603</td>\n",
       "      <td>0.125598</td>\n",
       "      <td>0.166868</td>\n",
       "      <td>0.111245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194743</td>\n",
       "      <td>0.076464</td>\n",
       "      <td>0.168269</td>\n",
       "      <td>0.112981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   control_gross  control_net  experiment_gross  experiment_net\n",
       "0       0.195051     0.101892          0.153061        0.049563\n",
       "1       0.188703     0.089859          0.147771        0.115924\n",
       "2       0.183718     0.104510          0.164027        0.089367\n",
       "3       0.186603     0.125598          0.166868        0.111245\n",
       "4       0.194743     0.076464          0.168269        0.112981"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign = pd.DataFrame()\n",
    "\n",
    "sign['control_gross'] = control['Enrollments'].dropna()/control['Clicks'].dropna()\n",
    "sign['control_net'] = control['Payments'].dropna()/control['Clicks'].dropna()\n",
    "sign['experiment_gross'] = experiment['Enrollments'].dropna()/experiment['Clicks'].dropna()\n",
    "sign['experiment_net'] = experiment['Payments'].dropna()/experiment['Clicks'].dropna()\n",
    "\n",
    "sign.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  4\n",
      "False:  19\n"
     ]
    }
   ],
   "source": [
    "print 'True: ', (sign['control_gross'] < sign['experiment_gross']).sum()\n",
    "print 'False: ', (sign['control_gross'] > sign['experiment_gross']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this results, I got the *p* value equal *0.0026* and it has Statistical Significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  10\n",
      "False:  13\n"
     ]
    }
   ],
   "source": [
    "print 'True: ', (sign['control_net'] < sign['experiment_net']).sum()\n",
    "print 'False: ', (sign['control_net'] > sign['experiment_net']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this results, I got the *p* value equal *0.6776* and it hasn't Statistical Significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "I would not use Bonferroni correction in this case. Bonferroni correction needs all metrics to be significantly different. This is not what we do in our experiment. We have Gross Conversion that need to be significant, and Net Conversion that need to be insignificant.\n",
    "\n",
    "- **Gross conversion:** Need significant\n",
    "- **Net conversion:** doesn't need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation\n",
    "\n",
    "Gross Conversion is good because it passes Udacity’s practical significance boundary. This means it reduces the number of students who feel not committed (in time/cost). However, even though Net Conversion is not statistically significance, its confidence interval touch practical significance boundary, which is not how Udacity wants. Udacity could lose potential money if the experiment launch. So my recommendation is further experiment or cancel if Udacity doesn’t have a time.\n",
    "\n",
    "- Gross Conversion: pass\n",
    "- Net Conversion: somehow pass, can loss potential money\n",
    "- Decision: risky. delay for further experiment or cancel the launch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow-Up Experiment\n",
    "\n",
    "Just for remember:\n",
    "- **free-trial** = 14 days\n",
    "- **frustrated students** = who left the free trial because they didn't have enough time\n",
    "\n",
    "In theory, a frustrated student is the one who cancels in the free period (14 days after signing) because he does not have enough time to devote himself to the course or because of the payment (hypothesis).\n",
    "To reduce the number of frustrated students, or rather to try to reduce I believe we can do the following activities:\n",
    "- What if we offered the first course for him to complete for free and as soon as he finished it, he would have to go back and be a Course Code Reviewer? In return, they have to be Code Reviewer, and finish the debt through payroll. They won't be given any salary until their debt finished.\n",
    "\n",
    "I have the following hypotheses because of this question:\n",
    "- We will be able to reduce the number of users who cancel very early in the courses.\n",
    "- We will have more engagement from the users after the incentive\n",
    "\n",
    "With this we managed to attack two points:\n",
    "- Code Reviewer from Udacity receives the review it makes. In doing so, Udacity would not have to pay it, that is, it would save (which would eventually compensate for the user's free course).\n",
    "- With the free course, the user will continue it until the end, even if it finishes in more time than the suggested one.\n",
    "\n",
    "But we have some risks with this idea:\n",
    "- The user can cancel his plan right in the middle.\n",
    "- End the course, but do not go back to being a Code Reviewer\n",
    "\n",
    "The hypothesis is that after they’re given an incentive, they become more serious and committed to complete the course. By doing this incentive, number of users who cancel early in the course is also significantly reduced, and boost them compared to ones which already committed.\n",
    "\n",
    "The unit of diversion is an user-id. Like free trial, the same user-id can’t follow the debt program twice. User-id is more cross-platform and more represent as an user than a cookie. User-ids that don’t enroll in the program, is not tracked in the experiment. The number of user-ids that are in debt program, but cancel at the end of the free trial is also not tracked.\n",
    "\n",
    "My tips are:\n",
    "\n",
    "- Not necessary to show warning\n",
    "- Start Debt Program\n",
    "- Risky, users break agreement\n",
    "    - Not become Udacity Code Reviewer\n",
    "    - Cancel in midway program\n",
    "- Hypothesis\n",
    "    - Non-serious users become more committed after incentive\n",
    "    - Number of users who cancel early is reduced\n",
    "    - Boost compared to already committed\n",
    "\n",
    "We can use Invariant metrics for this experiment:\n",
    "- **Number of cookies:** That is, number of unique cookies to view the course overview page.\n",
    "- **Number of clicks:** That is, number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger).\n",
    "- **Click-through-probability:** That is, number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page.\n",
    "- **Gross conversion:** That is, number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button.\n",
    "\n",
    "And Evaluation metrics:\n",
    "- **Debt Conversion:** That is, number of user-ids to click “Start Debt Program” divided by number of user-ids that enroll in the free trial.\n",
    "- **Debt-Net conversion:** That is, number of user-ids to click “Start Debt Program” divided by number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment)\n",
    "- **Net conversion:** That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
